{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fadd276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intelligibility eval\n"
     ]
    }
   ],
   "source": [
    "print('intelligibility eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c9c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from transformers) (4.46.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: torch in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: jiwer in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (4.0.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from jiwer) (3.9.7)\n",
      "Collecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp38-cp38-manylinux1_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from pandas==1.1.5) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from pandas==1.1.5) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from pandas==1.1.5) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/sidleal/anaconda3/envs/fs2/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5) (1.16.0)\n",
      "Downloading pandas-1.1.5-cp38-cp38-manylinux1_x86_64.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "Successfully installed pandas-1.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install jiwer\n",
    "!pip install pandas==1.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ddd67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"nilc-nlp/distil-whisper-coraa-mupe-asr\"\n",
    "#model_id = \"sidleal/distil-whisper-tarsila-asr-v1-200k\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    #model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "    model_id, torch_dtype=torch_dtype, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    torch_dtype=torch_dtype,\n",
    "    return_timestamps=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "def trancript_with_distil(file_path):\n",
    "    result = pipe(file_path)\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610a4195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidleal/anaconda3/envs/ipynb12/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "mas a gente que ia assim que você tinha que ser bar com os seus vejinhos\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = trancript_with_distil(\"/home/sidleal/sources/FastSpeech2/output/result/cmltts_entoa_prossegue/sp234/a gente ia ao cinema tinha em são paulo tem uns cinemas ótimos.wav\")\n",
    "print(\"----------------------------------------\")\n",
    "print(result)\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7929b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jiwer\n",
    "import jiwer.transforms as tr\n",
    "\n",
    "cer_transform = tr.Compose(\n",
    "    [\n",
    "        jiwer.ToLowerCase(),\n",
    "        jiwer.RemoveMultipleSpaces(),\n",
    "        jiwer.Strip(),\n",
    "        jiwer.ReduceToListOfListOfChars(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# It's the jiwer default transform\n",
    "wer_transform = jiwer.Compose([\n",
    "    jiwer.ToLowerCase(),\n",
    "    jiwer.RemoveMultipleSpaces(),\n",
    "    jiwer.Strip(),\n",
    "    jiwer.ReduceToListOfListOfWords(),\n",
    "])\n",
    "\n",
    "def compute_cer(reference, hypothesis):\n",
    "    reference = reference.lower()\n",
    "    hypothesis = hypothesis.lower()\n",
    "    cer = jiwer.wer(reference, hypothesis, truth_transform=cer_transform, hypothesis_transform=cer_transform)\n",
    "    return cer\n",
    "\n",
    "def compute_wer(reference, hypothesis):\n",
    "    reference = reference.lower()\n",
    "    hypothesis = hypothesis.lower()\n",
    "    wer = jiwer.wer(reference, hypothesis, truth_transform=wer_transform, hypothesis_transform=wer_transform)\n",
    "    return wer\n",
    "\n",
    "\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZÇÃÀÁÂÊÉÍÓÔÕÚÛabcdefghijklmnopqrstuvwxyzçãàáâêéíóôõũúû1234567890%\\\\-\\n/\\\\ \"\n",
    "\n",
    "\n",
    "def replace_special_tokens_and_normalize(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    map_words = {\n",
    "        \"éh\": \"eh\",\n",
    "        \"ehm\": \"eh\",\n",
    "        \"ehn\": \"eh\",\n",
    "        \"hum\": \"uh\",\n",
    "        \"hm\": \"uh\",\n",
    "        \"uhm\": \"uh\",\n",
    "        \"hã\": \"ah\",\n",
    "        \"ãh\": \"ah\",\n",
    "        \"ã\":  \"ah\",\n",
    "        \"hmm\": \"uh\",\n",
    "        \"mm\": \"uh\",\n",
    "        \"mhm\": \"uh\"\n",
    "    }\n",
    "\n",
    "    text = re.sub(\"h+\", \"h\", text)\n",
    "    text = re.sub(\"[^{}]\".format(alphabet+\" \"), \" \", text)\n",
    "    text = re.sub(\"[ ]+\", \" \", text)\n",
    "\n",
    "    words = text.split(' ')\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word == '' or word == ' ':\n",
    "            continue\n",
    "        if word in map_words:\n",
    "            new_words.append(map_words[word])\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "\n",
    "def calculate_wer_cer(reference, hypothesis):\n",
    "    if reference.strip() == '' or hypothesis.strip() == '':\n",
    "        return 1, 1\n",
    "    wer = compute_wer(reference, hypothesis)\n",
    "    cer = compute_cer(reference, hypothesis)\n",
    "    return wer, cer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac5f639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>human</th>\n",
       "      <th>ground</th>\n",
       "      <th>auto</th>\n",
       "      <th>prosodic</th>\n",
       "      <th>ground_wer</th>\n",
       "      <th>ground_cer</th>\n",
       "      <th>auto_wer</th>\n",
       "      <th>auto_cer</th>\n",
       "      <th>prosodic_wer</th>\n",
       "      <th>prosodic_cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP_DID_234_seg_229.22_253.82.wav</td>\n",
       "      <td>bom um bom artista é o que desempenha o papel ...</td>\n",
       "      <td>bom um bom artista é o que desempenha o papel ...</td>\n",
       "      <td>tão bom artista é o que desempenha o papel na ...</td>\n",
       "      <td>dom um bom artista</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5535</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>0.9336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP_DID_234_seg_305.70_309.20.wav</td>\n",
       "      <td>a inês que tem assistido várias peças mas eu n...</td>\n",
       "      <td>aí nesse que tenha sido várias peças mas eu nã...</td>\n",
       "      <td>aí que tem que levar a visita da casa assim só...</td>\n",
       "      <td>as buro e tem tem que tem as mas essas essas p...</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.9412</td>\n",
       "      <td>0.6790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP_DID_234_seg_413.92_427.90.wav</td>\n",
       "      <td>sei lá eu sabe o que eu a o que eu noto que o ...</td>\n",
       "      <td>sei lá eu sabe que eu que eu noto que o teatro...</td>\n",
       "      <td>se lá eu saber o que o homem é motor eu peguei...</td>\n",
       "      <td>se lá eu sabia que geovrô não tinha que ver né...</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.6773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP_DID_234_seg_1146.79_1147.03.wav</td>\n",
       "      <td>fala</td>\n",
       "      <td>tando</td>\n",
       "      <td>fava</td>\n",
       "      <td>fala</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP_DID_234_seg_1207.41_1208.51.wav</td>\n",
       "      <td>ai que horror</td>\n",
       "      <td>ai que horror</td>\n",
       "      <td>aí que eu vou</td>\n",
       "      <td>ah em que horror</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4615</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.3077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 path  \\\n",
       "0    SP_DID_234_seg_229.22_253.82.wav   \n",
       "1    SP_DID_234_seg_305.70_309.20.wav   \n",
       "2    SP_DID_234_seg_413.92_427.90.wav   \n",
       "3  SP_DID_234_seg_1146.79_1147.03.wav   \n",
       "4  SP_DID_234_seg_1207.41_1208.51.wav   \n",
       "\n",
       "                                               human  \\\n",
       "0  bom um bom artista é o que desempenha o papel ...   \n",
       "1  a inês que tem assistido várias peças mas eu n...   \n",
       "2  sei lá eu sabe o que eu a o que eu noto que o ...   \n",
       "3                                               fala   \n",
       "4                                      ai que horror   \n",
       "\n",
       "                                              ground  \\\n",
       "0  bom um bom artista é o que desempenha o papel ...   \n",
       "1  aí nesse que tenha sido várias peças mas eu nã...   \n",
       "2  sei lá eu sabe que eu que eu noto que o teatro...   \n",
       "3                                              tando   \n",
       "4                                      ai que horror   \n",
       "\n",
       "                                                auto  \\\n",
       "0  tão bom artista é o que desempenha o papel na ...   \n",
       "1  aí que tem que levar a visita da casa assim só...   \n",
       "2  se lá eu saber o que o homem é motor eu peguei...   \n",
       "3                                               fava   \n",
       "4                                      aí que eu vou   \n",
       "\n",
       "                                            prosodic  ground_wer  ground_cer  \\\n",
       "0                                 dom um bom artista      0.0179      0.0148   \n",
       "1  as buro e tem tem que tem as mas essas essas p...      0.2353      0.1358   \n",
       "2  se lá eu sabia que geovrô não tinha que ver né...      0.1429      0.0818   \n",
       "3                                               fala      1.0000      1.0000   \n",
       "4                                   ah em que horror      0.0000      0.0000   \n",
       "\n",
       "   auto_wer  auto_cer  prosodic_wer  prosodic_cer  \n",
       "0    0.7500    0.5535        0.9464        0.9336  \n",
       "1    0.8824    0.6790        0.9412        0.6790  \n",
       "2    0.7959    0.6909        0.8367        0.6773  \n",
       "3    1.0000    0.2500        0.0000        0.0000  \n",
       "4    1.0000    0.4615        0.6667        0.3077  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sintetizar\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "file_path = \"/home/sidleal/sources/entoa-tts/experiments/sp_234_l1_transc_cer_wer.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db15ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"/home/sidleal/sources/FastSpeech2/output/result/cmltts_entoa_prossegue/sp234/\"\n",
    "\n",
    "for index, row in df.iterrows():    \n",
    "    human_value = row['human']\n",
    "    file_name = human_value + \".wav\"\n",
    "    if len(human_value) > 100:\n",
    "        file_name = human_value[:100] + \".wav\"\n",
    "    print(f\"Row {index}: {file_name} - {human_value}\")\n",
    "    result = trancript_with_distil(source_path + \"/\" + file_name)\n",
    "    print(\"-->\", result)\n",
    "    df.at[index, 'prossegue'] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1da9e759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>human</th>\n",
       "      <th>ground</th>\n",
       "      <th>auto</th>\n",
       "      <th>prosodic</th>\n",
       "      <th>ground_wer</th>\n",
       "      <th>ground_cer</th>\n",
       "      <th>auto_wer</th>\n",
       "      <th>auto_cer</th>\n",
       "      <th>prosodic_wer</th>\n",
       "      <th>prosodic_cer</th>\n",
       "      <th>prossegue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP_DID_234_seg_229.22_253.82.wav</td>\n",
       "      <td>bom um bom artista é o que desempenha o papel ...</td>\n",
       "      <td>bom um bom artista é o que desempenha o papel ...</td>\n",
       "      <td>tão bom artista é o que desempenha o papel na ...</td>\n",
       "      <td>dom um bom artista</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5535</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>0.9336</td>\n",
       "      <td>bombo artista é o que desempenhou até uma peça...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP_DID_234_seg_305.70_309.20.wav</td>\n",
       "      <td>a inês que tem assistido várias peças mas eu n...</td>\n",
       "      <td>aí nesse que tenha sido várias peças mas eu nã...</td>\n",
       "      <td>aí que tem que levar a visita da casa assim só...</td>\n",
       "      <td>as buro e tem tem que tem as mas essas essas p...</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.9412</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>a inesquec que tinha assistido várias peças ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP_DID_234_seg_413.92_427.90.wav</td>\n",
       "      <td>sei lá eu sabe o que eu a o que eu noto que o ...</td>\n",
       "      <td>sei lá eu sabe que eu que eu noto que o teatro...</td>\n",
       "      <td>se lá eu saber o que o homem é motor eu peguei...</td>\n",
       "      <td>se lá eu sabia que geovrô não tinha que ver né...</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>se não saber o que não ou eu moro do meu tempo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP_DID_234_seg_1146.79_1147.03.wav</td>\n",
       "      <td>fala</td>\n",
       "      <td>tando</td>\n",
       "      <td>fava</td>\n",
       "      <td>fala</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>fala pausa pausa pausa pausa pausa pausa pausa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP_DID_234_seg_1207.41_1208.51.wav</td>\n",
       "      <td>ai que horror</td>\n",
       "      <td>ai que horror</td>\n",
       "      <td>aí que eu vou</td>\n",
       "      <td>ah em que horror</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4615</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>aí que eu vou é que eu vou</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 path  \\\n",
       "0    SP_DID_234_seg_229.22_253.82.wav   \n",
       "1    SP_DID_234_seg_305.70_309.20.wav   \n",
       "2    SP_DID_234_seg_413.92_427.90.wav   \n",
       "3  SP_DID_234_seg_1146.79_1147.03.wav   \n",
       "4  SP_DID_234_seg_1207.41_1208.51.wav   \n",
       "\n",
       "                                               human  \\\n",
       "0  bom um bom artista é o que desempenha o papel ...   \n",
       "1  a inês que tem assistido várias peças mas eu n...   \n",
       "2  sei lá eu sabe o que eu a o que eu noto que o ...   \n",
       "3                                               fala   \n",
       "4                                      ai que horror   \n",
       "\n",
       "                                              ground  \\\n",
       "0  bom um bom artista é o que desempenha o papel ...   \n",
       "1  aí nesse que tenha sido várias peças mas eu nã...   \n",
       "2  sei lá eu sabe que eu que eu noto que o teatro...   \n",
       "3                                              tando   \n",
       "4                                      ai que horror   \n",
       "\n",
       "                                                auto  \\\n",
       "0  tão bom artista é o que desempenha o papel na ...   \n",
       "1  aí que tem que levar a visita da casa assim só...   \n",
       "2  se lá eu saber o que o homem é motor eu peguei...   \n",
       "3                                               fava   \n",
       "4                                      aí que eu vou   \n",
       "\n",
       "                                            prosodic  ground_wer  ground_cer  \\\n",
       "0                                 dom um bom artista      0.0179      0.0148   \n",
       "1  as buro e tem tem que tem as mas essas essas p...      0.2353      0.1358   \n",
       "2  se lá eu sabia que geovrô não tinha que ver né...      0.1429      0.0818   \n",
       "3                                               fala      1.0000      1.0000   \n",
       "4                                   ah em que horror      0.0000      0.0000   \n",
       "\n",
       "   auto_wer  auto_cer  prosodic_wer  prosodic_cer  \\\n",
       "0    0.7500    0.5535        0.9464        0.9336   \n",
       "1    0.8824    0.6790        0.9412        0.6790   \n",
       "2    0.7959    0.6909        0.8367        0.6773   \n",
       "3    1.0000    0.2500        0.0000        0.0000   \n",
       "4    1.0000    0.4615        0.6667        0.3077   \n",
       "\n",
       "                                           prossegue  \n",
       "0  bombo artista é o que desempenhou até uma peça...  \n",
       "1  a inesquec que tinha assistido várias peças ma...  \n",
       "2  se não saber o que não ou eu moro do meu tempo...  \n",
       "3  fala pausa pausa pausa pausa pausa pausa pausa...  \n",
       "4                         aí que eu vou é que eu vou  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe0134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():    \n",
    "    human_value = row['human']\n",
    "    prossegue_value = row['prossegue']\n",
    "    human_norm = replace_special_tokens_and_normalize(human_value)\n",
    "    prossegue_norm = replace_special_tokens_and_normalize(prossegue_value)\n",
    "    wer, cer = calculate_wer_cer(human_norm, prossegue_norm)\n",
    "    df.at[index, 'prossegue_wer'] = wer\n",
    "    df.at[index, 'prossegue_cer'] = cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "141624ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>human</th>\n",
       "      <th>ground</th>\n",
       "      <th>auto</th>\n",
       "      <th>prosodic</th>\n",
       "      <th>ground_wer</th>\n",
       "      <th>ground_cer</th>\n",
       "      <th>auto_wer</th>\n",
       "      <th>auto_cer</th>\n",
       "      <th>prosodic_wer</th>\n",
       "      <th>prosodic_cer</th>\n",
       "      <th>prossegue</th>\n",
       "      <th>prossegue_wer</th>\n",
       "      <th>prossegue_cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP_DID_234_seg_229.22_253.82.wav</td>\n",
       "      <td>bom um bom artista é o que desempenha o papel ...</td>\n",
       "      <td>bom um bom artista é o que desempenha o papel ...</td>\n",
       "      <td>tão bom artista é o que desempenha o papel na ...</td>\n",
       "      <td>dom um bom artista</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5535</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>0.9336</td>\n",
       "      <td>bombo artista é o que desempenhou até uma peça...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.708487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP_DID_234_seg_305.70_309.20.wav</td>\n",
       "      <td>a inês que tem assistido várias peças mas eu n...</td>\n",
       "      <td>aí nesse que tenha sido várias peças mas eu nã...</td>\n",
       "      <td>aí que tem que levar a visita da casa assim só...</td>\n",
       "      <td>as buro e tem tem que tem as mas essas essas p...</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.9412</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>a inesquec que tinha assistido várias peças ma...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.419753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP_DID_234_seg_413.92_427.90.wav</td>\n",
       "      <td>sei lá eu sabe o que eu a o que eu noto que o ...</td>\n",
       "      <td>sei lá eu sabe que eu que eu noto que o teatro...</td>\n",
       "      <td>se lá eu saber o que o homem é motor eu peguei...</td>\n",
       "      <td>se lá eu sabia que geovrô não tinha que ver né...</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>se não saber o que não ou eu moro do meu tempo...</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP_DID_234_seg_1146.79_1147.03.wav</td>\n",
       "      <td>fala</td>\n",
       "      <td>tando</td>\n",
       "      <td>fava</td>\n",
       "      <td>fala</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>fala pausa pausa pausa pausa pausa pausa pausa...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP_DID_234_seg_1207.41_1208.51.wav</td>\n",
       "      <td>ai que horror</td>\n",
       "      <td>ai que horror</td>\n",
       "      <td>aí que eu vou</td>\n",
       "      <td>ah em que horror</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4615</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>aí que eu vou é que eu vou</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.384615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 path  \\\n",
       "0    SP_DID_234_seg_229.22_253.82.wav   \n",
       "1    SP_DID_234_seg_305.70_309.20.wav   \n",
       "2    SP_DID_234_seg_413.92_427.90.wav   \n",
       "3  SP_DID_234_seg_1146.79_1147.03.wav   \n",
       "4  SP_DID_234_seg_1207.41_1208.51.wav   \n",
       "\n",
       "                                               human  \\\n",
       "0  bom um bom artista é o que desempenha o papel ...   \n",
       "1  a inês que tem assistido várias peças mas eu n...   \n",
       "2  sei lá eu sabe o que eu a o que eu noto que o ...   \n",
       "3                                               fala   \n",
       "4                                      ai que horror   \n",
       "\n",
       "                                              ground  \\\n",
       "0  bom um bom artista é o que desempenha o papel ...   \n",
       "1  aí nesse que tenha sido várias peças mas eu nã...   \n",
       "2  sei lá eu sabe que eu que eu noto que o teatro...   \n",
       "3                                              tando   \n",
       "4                                      ai que horror   \n",
       "\n",
       "                                                auto  \\\n",
       "0  tão bom artista é o que desempenha o papel na ...   \n",
       "1  aí que tem que levar a visita da casa assim só...   \n",
       "2  se lá eu saber o que o homem é motor eu peguei...   \n",
       "3                                               fava   \n",
       "4                                      aí que eu vou   \n",
       "\n",
       "                                            prosodic  ground_wer  ground_cer  \\\n",
       "0                                 dom um bom artista      0.0179      0.0148   \n",
       "1  as buro e tem tem que tem as mas essas essas p...      0.2353      0.1358   \n",
       "2  se lá eu sabia que geovrô não tinha que ver né...      0.1429      0.0818   \n",
       "3                                               fala      1.0000      1.0000   \n",
       "4                                   ah em que horror      0.0000      0.0000   \n",
       "\n",
       "   auto_wer  auto_cer  prosodic_wer  prosodic_cer  \\\n",
       "0    0.7500    0.5535        0.9464        0.9336   \n",
       "1    0.8824    0.6790        0.9412        0.6790   \n",
       "2    0.7959    0.6909        0.8367        0.6773   \n",
       "3    1.0000    0.2500        0.0000        0.0000   \n",
       "4    1.0000    0.4615        0.6667        0.3077   \n",
       "\n",
       "                                           prossegue  prossegue_wer  \\\n",
       "0  bombo artista é o que desempenhou até uma peça...       0.875000   \n",
       "1  a inesquec que tinha assistido várias peças ma...       0.647059   \n",
       "2  se não saber o que não ou eu moro do meu tempo...       0.877551   \n",
       "3  fala pausa pausa pausa pausa pausa pausa pausa...       8.000000   \n",
       "4                         aí que eu vou é que eu vou       2.333333   \n",
       "\n",
       "   prossegue_cer  \n",
       "0       0.708487  \n",
       "1       0.419753  \n",
       "2       0.712329  \n",
       "3      12.000000  \n",
       "4       1.384615  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaf97efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sp_234_l1_transc_wer_cer_prossegue.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3acadcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER WHISPER: 49.60\n",
      "WER PROSSEGUE: 76.71\n",
      "T-statistic: -4.7670 (-4.76701094136319) P-value: 0.0000 (2.263081647713262e-06)\n",
      "WER MANUAL: 43.18\n",
      "WER PROSSEGUE: 76.71\n",
      "T-statistic: -5.8896 (-5.889587761951122) P-value: 0.0000 (5.940187933927828e-09)\n",
      "WER HUMAN: 16.06\n",
      "WER PROSSEGUE: 76.71\n",
      "T-statistic: -10.9522 (-10.95220806135418) P-value: 0.0000 (6.317010334490647e-26)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "#import pandas as pd\n",
    "#df = pd.read_csv('sp_234_l1_transc_wer_cer_prossegue.csv')\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(df[\"auto_wer\"], df[\"prossegue_wer\"])\n",
    "\n",
    "print(f\"WER WHISPER: {df[\"auto_wer\"].mean()*100:.2f}\")\n",
    "print(f\"WER PROSSEGUE: {df[\"prossegue_wer\"].mean()*100:.2f}\")\n",
    "\n",
    "print(f\"T-statistic: {t_statistic:.4f} ({t_statistic})\", f\"P-value: {p_value:.4f} ({p_value})\" )\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(df[\"prosodic_wer\"], df[\"prossegue_wer\"])\n",
    "\n",
    "print(f\"WER MANUAL: {df[\"prosodic_wer\"].mean()*100:.2f}\")\n",
    "print(f\"WER PROSSEGUE: {df[\"prossegue_wer\"].mean()*100:.2f}\")\n",
    "\n",
    "print(f\"T-statistic: {t_statistic:.4f} ({t_statistic})\", f\"P-value: {p_value:.4f} ({p_value})\" )\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(df[\"ground_wer\"], df[\"prossegue_wer\"])\n",
    "\n",
    "print(f\"WER HUMAN: {df[\"ground_wer\"].mean()*100:.2f}\")\n",
    "print(f\"WER PROSSEGUE: {df[\"prossegue_wer\"].mean()*100:.2f}\")\n",
    "\n",
    "print(f\"T-statistic: {t_statistic:.4f} ({t_statistic})\", f\"P-value: {p_value:.4f} ({p_value})\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dbf8bf",
   "metadata": {},
   "source": [
    "# old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05288eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "file_name = 'prossegue_cer_wer_output.csv'\n",
    "\n",
    "folder_path = '/home/sidleal/sources/FastSpeech2/output/result/cmltts_entoa_prossegue/sp_234'\n",
    "\n",
    "with open(file_name, 'a', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    csv_data = [\"audio_name\", \"human_text\", \"human_text_norm\", \"transcript_original\", \"transcript_synthesized\", \"cer_original\", \"cer_synthesized\", \"wer_original\", \"wer_synthesized\"]\n",
    "    writer.writerow(csv_data)\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            audio_name = filename[:-8]\n",
    "            original_audio_name = filename[:-4]\n",
    "            synth_audio_name = filename[:-4] + \"_synthesized.wav\"\n",
    "\n",
    "            with open(f\"{folder_path}/{filename}\", encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "                text_norm = replace_special_tokens_and_normalize(text)\n",
    "\n",
    "                transcript_ori = trancript_with_distil(f\"{folder_path}/{original_audio_name}\")\n",
    "                transcript_syn = trancript_with_distil(f\"{folder_path}/{synth_audio_name}\")\n",
    "\n",
    "                transcript_ori_norm = replace_special_tokens_and_normalize(transcript_ori)\n",
    "                transcript_syn_norm = replace_special_tokens_and_normalize(transcript_syn)\n",
    "\n",
    "                ori_wer_cer = calculate_wer_cer(text_norm, transcript_ori_norm)\n",
    "                syn_wer_cer = calculate_wer_cer(text_norm, transcript_syn_norm)\n",
    "\n",
    "                print(\"--------------------------------\")\n",
    "                print(audio_name)\n",
    "                print(\"-\", text)\n",
    "                print(\"-\", text_norm)\n",
    "                print(\"-\", original_audio_name)\n",
    "                print(\"-\", synth_audio_name)\n",
    "                print(\"-\", transcript_ori_norm)\n",
    "                print(\"-\", transcript_syn_norm)\n",
    "                print(ori_wer_cer)\n",
    "                print(syn_wer_cer)\n",
    "\n",
    "                csv_data = [audio_name, text, text_norm, transcript_ori_norm, transcript_syn_norm, ori_wer_cer[1], syn_wer_cer[1], ori_wer_cer[0], syn_wer_cer[0]]\n",
    "                writer.writerow(csv_data)\n",
    "\n",
    "            #break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d8923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER ORIGINAL: 13.70\n",
      "WER SINTETIZADO: 23.86\n",
      "T-statistic: -6.1082 (-6.108212784547283)\n",
      "P-value: 0.0000 (5.242308079569724e-09)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(df[\"wer_original\"], df[\"wer_synthesized\"])\n",
    "\n",
    "print(f\"WER ORIGINAL: {df[\"wer_original\"].mean()*100:.2f}\")\n",
    "print(f\"WER SINTETIZADO: {df[\"wer_synthesized\"].mean()*100:.2f}\")\n",
    "\n",
    "print(f\"T-statistic: {t_statistic:.4f} ({t_statistic})\")\n",
    "print(f\"P-value: {p_value:.4f} ({p_value})\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ba50a",
   "metadata": {},
   "source": [
    "# f5tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0658bc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_name</th>\n",
       "      <th>human_text</th>\n",
       "      <th>human_text_norm</th>\n",
       "      <th>transcript_original</th>\n",
       "      <th>transcript_synthesized</th>\n",
       "      <th>cer_original</th>\n",
       "      <th>cer_synthesized</th>\n",
       "      <th>wer_original</th>\n",
       "      <th>wer_synthesized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sr16k_mono_0027-CP011_1250.69-1261.3</td>\n",
       "      <td>Ô Jorge, é o seguinte, a gente esqueceu de avi...</td>\n",
       "      <td>ô jorge é o seguinte a gente esqueceu de avisa...</td>\n",
       "      <td>o jorge é o seguinte a gente esqueceu de avisa...</td>\n",
       "      <td>eu já é o seguinte a gente esqueceu de avisar ...</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>0.211180</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.387097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sr16k_mono_0038-CP015_950.037-979.634</td>\n",
       "      <td>E eu gostaria de lembrar que um dos motivos da...</td>\n",
       "      <td>e eu gostaria de lembrar que um dos motivos da...</td>\n",
       "      <td>eu gostaria de lembrar que um dos motivos dess...</td>\n",
       "      <td>eu gostaria de lembrar que os motivos da da re...</td>\n",
       "      <td>0.104623</td>\n",
       "      <td>0.085158</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.118421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sr16k_mono_0067-CP546_1576.56-1591.05</td>\n",
       "      <td>É. é que Veja bem, essa experiência, eu gostar...</td>\n",
       "      <td>é é que veja bem essa experiência eu gostaria ...</td>\n",
       "      <td>é eh que veja bem essa experiência eu gostaria...</td>\n",
       "      <td>é que veja bem essa experiência eu gostaria qu...</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.073469</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.212766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sr16k_mono_0082-CP707_1508.09-1518.64</td>\n",
       "      <td>Mas eu gostaria... Claudio, dá dá só uma uma u...</td>\n",
       "      <td>mas eu gostaria claudio dá dá só uma uma uma a...</td>\n",
       "      <td>mas eu gostaria caldo dá dá só uma uma aperfei...</td>\n",
       "      <td>você gostaria de é de dada só uma uma aperfeiç...</td>\n",
       "      <td>0.112583</td>\n",
       "      <td>0.172185</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.321429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sr16k_mono_0079-CP623_853.479-861.621</td>\n",
       "      <td>Foi nesse contraponto que eu tentei compreende...</td>\n",
       "      <td>foi nesse contraponto que eu tentei compreende...</td>\n",
       "      <td>então foi nesse contraponto que eu tentei comp...</td>\n",
       "      <td>foi nesse contrário conto que eu tentei compre...</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              audio_name  \\\n",
       "0   sr16k_mono_0027-CP011_1250.69-1261.3   \n",
       "1  sr16k_mono_0038-CP015_950.037-979.634   \n",
       "2  sr16k_mono_0067-CP546_1576.56-1591.05   \n",
       "3  sr16k_mono_0082-CP707_1508.09-1518.64   \n",
       "4  sr16k_mono_0079-CP623_853.479-861.621   \n",
       "\n",
       "                                          human_text  \\\n",
       "0  Ô Jorge, é o seguinte, a gente esqueceu de avi...   \n",
       "1  E eu gostaria de lembrar que um dos motivos da...   \n",
       "2  É. é que Veja bem, essa experiência, eu gostar...   \n",
       "3  Mas eu gostaria... Claudio, dá dá só uma uma u...   \n",
       "4  Foi nesse contraponto que eu tentei compreende...   \n",
       "\n",
       "                                     human_text_norm  \\\n",
       "0  ô jorge é o seguinte a gente esqueceu de avisa...   \n",
       "1  e eu gostaria de lembrar que um dos motivos da...   \n",
       "2  é é que veja bem essa experiência eu gostaria ...   \n",
       "3  mas eu gostaria claudio dá dá só uma uma uma a...   \n",
       "4  foi nesse contraponto que eu tentei compreende...   \n",
       "\n",
       "                                 transcript_original  \\\n",
       "0  o jorge é o seguinte a gente esqueceu de avisa...   \n",
       "1  eu gostaria de lembrar que um dos motivos dess...   \n",
       "2  é eh que veja bem essa experiência eu gostaria...   \n",
       "3  mas eu gostaria caldo dá dá só uma uma aperfei...   \n",
       "4  então foi nesse contraponto que eu tentei comp...   \n",
       "\n",
       "                              transcript_synthesized  cer_original  \\\n",
       "0  eu já é o seguinte a gente esqueceu de avisar ...      0.037267   \n",
       "1  eu gostaria de lembrar que os motivos da da re...      0.104623   \n",
       "2  é que veja bem essa experiência eu gostaria qu...      0.102041   \n",
       "3  você gostaria de é de dada só uma uma aperfeiç...      0.112583   \n",
       "4  foi nesse contrário conto que eu tentei compre...      0.148148   \n",
       "\n",
       "   cer_synthesized  wer_original  wer_synthesized  \n",
       "0         0.211180      0.161290         0.387097  \n",
       "1         0.085158      0.184211         0.118421  \n",
       "2         0.073469      0.170213         0.212766  \n",
       "3         0.172185      0.214286         0.321429  \n",
       "4         0.194444      0.263158         0.421053  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = 'cer_wer_output.csv'\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('cer_wer_output.csv')\n",
    "\n",
    "file_name = 'cer_wer_output_v2.csv'\n",
    "\n",
    "folder_path = 'resulting_audios_cv-fn'\n",
    "\n",
    "with open(file_name, 'a', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    csv_data = [\"audio_name\", \"human_text\", \"human_text_norm\", \"transcript_original\", \"transcript_synthesized_yourtts\", \"transcript_synthesized_f5tts_cv\", \"cer_original\", \"cer_synthesized_yourtts\", \"cer_synthesized_f5tts_cv\", \"wer_original\", \"wer_synthesized_yourtts\", \"wer_synthesized_f5tts_cv\"]\n",
    "    writer.writerow(csv_data)\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            audio_name = filename[:-4]\n",
    "            print(audio_name)\n",
    "\n",
    "            audio_key = f\"sr16k_mono_{audio_name[6:]}\"\n",
    "            print(audio_key)\n",
    "\n",
    "            row = df.query(f\"audio_name == '{audio_key}'\")\n",
    "            print(row['audio_name'].iloc[0])\n",
    "            print(row['human_text_norm'].iloc[0])\n",
    "            print(\"-------\")\n",
    "            \n",
    "            text_norm = replace_special_tokens_and_normalize(row['human_text_norm'].iloc[0])\n",
    "\n",
    "            transcript_f5cv = trancript_with_distil(f\"{folder_path}/{filename}\")\n",
    "            transcript_f5cv_norm = replace_special_tokens_and_normalize(transcript_f5cv)\n",
    "\n",
    "            f5cv_wer_cer = calculate_wer_cer(text_norm, transcript_f5cv_norm)\n",
    "\n",
    "            print(\"-\", text_norm)\n",
    "            print(\"-\", transcript_f5cv_norm)\n",
    "            print(f5cv_wer_cer)\n",
    "\n",
    "            csv_data = [audio_key, row[\"human_text\"].iloc[0], row[\"human_text_norm\"].iloc[0], row[\"transcript_original\"].iloc[0], row[\"transcript_synthesized\"].iloc[0], transcript_f5cv_norm, row[\"cer_original\"].iloc[0], row[\"cer_synthesized\"].iloc[0], f5cv_wer_cer[1], row[\"wer_original\"].iloc[0], row[\"wer_synthesized\"].iloc[0], f5cv_wer_cer[0]]\n",
    "            writer.writerow(csv_data)\n",
    "\n",
    "            #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c430e840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER ORIGINAL: 13.60\n",
      "WER SINTETIZADO F5 CV: 18.12\n",
      "T-statistic: -3.0251 (-3.025088762473149)\n",
      "P-value: 0.0028 (0.0028187078083642975)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "file_name = 'cer_wer_output_v2.csv'\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(df[\"wer_original\"], df[\"wer_synthesized_f5tts_cv\"])\n",
    "\n",
    "print(f\"WER ORIGINAL: {df[\"wer_original\"].mean()*100:.2f}\")\n",
    "print(f\"WER SINTETIZADO F5 CV: {df[\"wer_synthesized_f5tts_cv\"].mean()*100:.2f}\")\n",
    "\n",
    "print(f\"T-statistic: {t_statistic:.4f} ({t_statistic})\")\n",
    "print(f\"P-value: {p_value:.4f} ({p_value})\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8431b903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER ORIGINAL: 23.77\n",
      "WER SINTETIZADO F5 CV: 18.12\n",
      "T-statistic: 3.6120 (3.6120189458795777)\n",
      "P-value: 0.0004 (0.0003859933928752929)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "file_name = 'cer_wer_output_v2.csv'\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(df[\"wer_synthesized_yourtts\"], df[\"wer_synthesized_f5tts_cv\"])\n",
    "\n",
    "print(f\"WER ORIGINAL: {df[\"wer_synthesized_yourtts\"].mean()*100:.2f}\")\n",
    "print(f\"WER SINTETIZADO F5 CV: {df[\"wer_synthesized_f5tts_cv\"].mean()*100:.2f}\")\n",
    "\n",
    "print(f\"T-statistic: {t_statistic:.4f} ({t_statistic})\")\n",
    "print(f\"P-value: {p_value:.4f} ({p_value})\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipynb12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
